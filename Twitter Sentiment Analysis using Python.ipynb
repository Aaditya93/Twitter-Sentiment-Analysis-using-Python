{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4a3c93-8019-4373-afc0-1923ee42e615",
   "metadata": {},
   "source": [
    "# 1. Initial Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e8b9490-b85f-4b76-a496-9ca7cfa4074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba706d-0042-48a6-81eb-614231712a73",
   "metadata": {},
   "source": [
    "# Load the Twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b69dbf56-bcf9-490c-af67-fe05e8021a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/aadityashewale/Downloads/twitter_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba9a75-6edd-4f3e-b126-ca58fcf717c9",
   "metadata": {},
   "source": [
    "# Text Preprocessing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "848ed111-65c8-49bb-b22b-e2bbcd5de54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aadityashewale/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords') \n",
    "stemmer = nltk.SnowballStemmer(\"english\")  \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd1784-9fe2-4d7b-b7a3-5407e5346378",
   "metadata": {},
   "source": [
    "# Text Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfd78656-fc23-4dbb-9ff1-c9eec8a7bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove square brackets and their contents\n",
    "    text = re.sub('\\\\[.*?\\\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub('https?://\\\\S+|www\\\\.\\\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    # Remove newlines\n",
    "    text = re.sub('\\\\n', '', text)\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub('\\\\w*\\\\d\\\\w*', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Apply stemming\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8831e-a8ce-4688-9ea2-5d4cf5f66bb8",
   "metadata": {},
   "source": [
    "# Apply cleaning function to tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4d8091a-e47d-46c0-a2da-263b0f2f8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aafa25-6971-4bdc-ae63-d116ca95873d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82a5bcf7-c7b8-427f-b944-5c4fe7107dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/aadityashewale/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')  # Download VADER lexicon\n",
    "sentiments = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d561c-4138-4a84-8c02-ffe2a4db3872",
   "metadata": {},
   "source": [
    "# Calculate sentiment scores for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da245842-bacd-4cb9-8bc2-7cbe9bdba561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"tweet\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7af7f-8b49-4a38-abd9-1451579fd48d",
   "metadata": {},
   "source": [
    "# Sentiment Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd5a20fc-e45a-40ab-b30c-8f7be3781dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(a, b, c):\n",
    "    \"\"\"\n",
    "    Determine overall sentiment based on cumulative scores\n",
    "    a: positive score\n",
    "    b: negative score\n",
    "    c: neutral score\n",
    "    \"\"\"\n",
    "    if (a > b) and (a > c):\n",
    "        print(\"Positive ðŸ˜Š \")\n",
    "    elif (b > a) and (b > c):\n",
    "        print(\"Negative ðŸ˜  \")\n",
    "    else:\n",
    "        print(\"Neutral ðŸ™‚ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0f8d2-f737-4037-96f3-8d2d2b10d08c",
   "metadata": {},
   "source": [
    "# Calculate total sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bbebe99-f6aa-43f6-9952-730ad58afc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(data[\"Positive\"])  # Total positive score\n",
    "y = sum(data[\"Negative\"])  # Total negative score\n",
    "z = sum(data[\"Neutral\"])   # Total neutral score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca3f22-212f-4869-ba53-518267d4e823",
   "metadata": {},
   "source": [
    "# Print final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36ad81a9-a8b9-4705-b616-12c2ddbfb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  2880.086\n",
      "Negative:  7201.021\n",
      "Neutral:  14696.888\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", x)\n",
    "print(\"Negative: \", y)\n",
    "print(\"Neutral: \", z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
